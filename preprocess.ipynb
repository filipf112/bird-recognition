{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76369622-7a77-40b1-8f7c-8b0256ca30b8",
   "metadata": {},
   "source": [
    "# Zamiana mp3 na wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400197fd-a754-4ab6-a3f2-6254d1c498be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "import os\n",
    "\n",
    "# Ścieżka do folderu z plikami mp3\n",
    "mp3_folder = r\"D:\\sieci_neuronowe\\projekt-sieci-neuronowe\\data\\Parus_major\"\n",
    "\n",
    "# Ścieżka do folderu, gdzie zostaną zapisane pliki wav\n",
    "wav_folder = r\"D:\\sieci_neuronowe\\projekt-sieci-neuronowe\\data\\wav\\Parus_major\"\n",
    "\n",
    "\n",
    "\n",
    "# Upewnij się, że folder docelowy istnieje, jeśli nie, to go utwórz\n",
    "if not os.path.exists(wav_folder):\n",
    "    os.makedirs(wav_folder)\n",
    "\n",
    "# Iteruj przez pliki w folderze mp3\n",
    "for file in os.listdir(mp3_folder):\n",
    "    if file.endswith(\".mp3\"):\n",
    "        mp3_path = os.path.join(mp3_folder, file)\n",
    "        wav_path = os.path.join(wav_folder, os.path.splitext(file)[0] + \".wav\")\n",
    "        \n",
    "        try:\n",
    "            # Wczytaj plik mp3\n",
    "            audio = AudioSegment.from_mp3(mp3_path)\n",
    "            \n",
    "            # Zapisz jako plik wav\n",
    "            audio.export(wav_path, format=\"wav\")\n",
    "            print(f\"Plik {file} został przekonwertowany.\")\n",
    "        except CouldntDecodeError:\n",
    "            print(f\"Nie można przekonwertować pliku {file}. Plik jest uszkodzony lub nieobsługiwany.\")\n",
    "            continue\n",
    "\n",
    "print(\"Konwersja zakończona.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc87022-978e-47c0-af4a-8605edbe8084",
   "metadata": {},
   "source": [
    "# Funkcje wykorzystywane do przetwarzania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d071fd-f58a-4eee-9301-92bee5e52e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "\n",
    "def normalize_wav(wav):\n",
    "    # Convert to float32 for normalization\n",
    "    wav = tf.cast(wav, tf.float32)\n",
    "    # Normalize the waveform\n",
    "    max_amp = tf.reduce_max(tf.abs(wav))\n",
    "    wav /= max_amp\n",
    "    return wav\n",
    "\n",
    "def split_wav_into_chunks(wav, chunk_length=3):\n",
    "    # Calculate number of samples per chunk\n",
    "    chunk_samples = chunk_length * 16000  # Assuming 16 kHz sample rate\n",
    "    # Calculate total number of chunks\n",
    "    num_chunks = len(wav) // chunk_samples\n",
    "    # Truncate the wav to fit an integer number of chunks\n",
    "    wav = wav[:num_chunks * chunk_samples]\n",
    "    # Reshape the wav into chunks\n",
    "    wav_chunks = tf.reshape(wav, (num_chunks, chunk_samples))\n",
    "    return wav_chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501cb4f2-9991-4128-a1e5-59a9bb2986bc",
   "metadata": {},
   "source": [
    "# Przykładowy plik podzielony na segmenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0cb2c-17fe-4820-ace2-70c79317aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize CAPUCHIN_FILE\n",
    "\n",
    "CAPUCHIN_FILE = os.path.join('data1', 'Anser_anser', 'Anser211456.wav')\n",
    "NOT_CAPUCHIN_FILE = os.path.join('data1', 'Parsed_Not_Capuchinbird_Clips', 'afternoon-birds-song-in-forest-0.wav')\n",
    "\n",
    "capuchin_wave = load_wav_16k_mono(CAPUCHIN_FILE)\n",
    "capuchin_wave = normalize_wav(capuchin_wave)\n",
    "\n",
    "# Split into chunks\n",
    "capuchin_chunks = split_wav_into_chunks(capuchin_wave)\n",
    "\n",
    "# Initialize lists to store correctness and colors\n",
    "correctness = []\n",
    "colors = []\n",
    "\n",
    "# Determine correctness of each chunk\n",
    "for chunk in capuchin_chunks:\n",
    "    # Calculate number of times amplitude > 0.3\n",
    "    high_amplitude_count = tf.reduce_sum(tf.cast(chunk > 0.6, tf.int32))\n",
    "    # Check if count is greater than or equal to 3\n",
    "    if high_amplitude_count >= 3:\n",
    "        correctness.append(True)\n",
    "        colors.append('blue')\n",
    "    else:\n",
    "        correctness.append(False)\n",
    "        colors.append('red')\n",
    "\n",
    "# Plot the original waveform\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(capuchin_wave, label='Recording Waveform')\n",
    "\n",
    "# Plot each chunk with correct color\n",
    "for i, (chunk, correct, color) in enumerate(zip(capuchin_chunks, correctness, colors)):\n",
    "    chunk_start = i * chunk.shape[0]\n",
    "    chunk_end = (i + 1) * chunk.shape[0]\n",
    "    plt.plot(range(chunk_start, chunk_end), chunk, label=f'Chunk {i+1}', color=color if correct else 'red')\n",
    "\n",
    "plt.title('Anser_anser Waveform and Its Chunks (Correct/Incorrect)')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e43a3b-ea11-4429-b4bf-74b69a0115dc",
   "metadata": {},
   "source": [
    "# Pobieranie spekrogramów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32538b4-56cc-4f40-a1cd-6e6de60adfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DATA_FOLDER = 'data1'\n",
    "SPECTRO_FOLDER = os.path.join(DATA_FOLDER, 'Spectro_v2')\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "def normalize_wav(wav):\n",
    "    # Convert to float32 for normalization\n",
    "    wav = tf.cast(wav, tf.float32)\n",
    "    # Normalize the waveform\n",
    "    max_amp = tf.reduce_max(tf.abs(wav))\n",
    "    wav /= max_amp\n",
    "    return wav\n",
    "\n",
    "def split_wav_into_chunks(wav, chunk_length=2):\n",
    "    # Calculate number of samples per chunk\n",
    "    chunk_samples = chunk_length * 16000  # Assuming 16 kHz sample rate\n",
    "    # Calculate total number of chunks\n",
    "    num_chunks = len(wav) // chunk_samples\n",
    "    # Truncate the wav to fit an integer number of chunks\n",
    "    wav = wav[:num_chunks * chunk_samples]\n",
    "    # Reshape the wav into chunks\n",
    "    wav_chunks = tf.reshape(wav, (num_chunks, chunk_samples))\n",
    "    return wav_chunks\n",
    "\n",
    "def save_spectro(correct_chunks, folder_name, recording_name):\n",
    "    spectro_folder = os.path.join(SPECTRO_FOLDER, folder_name)\n",
    "    if not os.path.exists(spectro_folder):\n",
    "        os.makedirs(spectro_folder)\n",
    "    \n",
    "    for i, chunk in enumerate(correct_chunks):\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.specgram(chunk.numpy(), Fs=16000)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(spectro_folder, f'{recording_name}_correct_chunk_{i}.jpg'), bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "# Iterate through each genre folder\n",
    "for genre_folder in os.listdir(DATA_FOLDER):\n",
    "    genre_path = os.path.join(DATA_FOLDER, genre_folder)\n",
    "    if os.path.isdir(genre_path):\n",
    "        print(\"Processing genre:\", genre_folder)\n",
    "        \n",
    "        # Iterate through each recording within the genre folder\n",
    "        for recording_name in os.listdir(genre_path):\n",
    "            recording_path = os.path.join(genre_path, recording_name)\n",
    "            if recording_name.endswith(\".wav\"):\n",
    "                print(\"Processing recording:\", recording_name)\n",
    "\n",
    "                try:\n",
    "                    # Load and normalize the WAV file\n",
    "                    wave = load_wav_16k_mono(recording_path)\n",
    "                    wave = normalize_wav(wave)\n",
    "\n",
    "                    # Split into chunks\n",
    "                    chunks = split_wav_into_chunks(wave)\n",
    "\n",
    "                    # Initialize list to store correctness\n",
    "                    correctness = []\n",
    "\n",
    "                    # Determine correctness of each chunk\n",
    "                    for chunk_index, chunk in enumerate(chunks):\n",
    "                        # Calculate number of times amplitude > 0.3\n",
    "                        high_amplitude_count = tf.reduce_sum(tf.cast(chunk > 0.65, tf.int32))\n",
    "                        # Check if count is greater than or equal to 3\n",
    "                        if high_amplitude_count >= 3:\n",
    "                            correctness.append(True)\n",
    "                        else:\n",
    "                            correctness.append(False)\n",
    "\n",
    "                    # Save spectrogram for correct chunks\n",
    "                    correct_chunks = [chunk for chunk, correct in zip(chunks, correctness) if correct]\n",
    "                    save_spectro(correct_chunks, genre_folder, os.path.splitext(recording_name)[0])\n",
    "\n",
    "                    print(\"Spectrograms saved successfully!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing {recording_name}: {e}\")\n",
    "                    continue\n",
    "\n",
    "print(\"All recordings processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d04881d-8c51-4531-841d-581ed91cba89",
   "metadata": {},
   "source": [
    "# Tworzenie spektrogramów Mela\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a25708-4d86-4059-9964-079b326176ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.exceptions import CouldntDecodeError\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "DATA_FOLDER = 'data1'\n",
    "SPECTRO_FOLDER = 'mel_v2'\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels)\n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav\n",
    "\n",
    "def normalize_wav(wav):\n",
    "    # Convert to float32 for normalization\n",
    "    wav = tf.cast(wav, tf.float32)\n",
    "    # Normalize the waveform\n",
    "    max_amp = tf.reduce_max(tf.abs(wav))\n",
    "    wav /= max_amp\n",
    "    return wav\n",
    "\n",
    "def split_wav_into_chunks(wav, chunk_length=2):\n",
    "    # Calculate number of samples per chunk\n",
    "    chunk_samples = chunk_length * 16000  # Assuming 16 kHz sample rate\n",
    "    # Calculate total number of chunks\n",
    "    num_chunks = len(wav) // chunk_samples\n",
    "    # Truncate the wav to fit an integer number of chunks\n",
    "    wav = wav[:num_chunks * chunk_samples]\n",
    "    # Reshape the wav into chunks\n",
    "    wav_chunks = tf.reshape(wav, (num_chunks, chunk_samples))\n",
    "    return wav_chunks\n",
    "\n",
    "def save_mel_spectrograms(correct_chunks, folder_name, recording_name):\n",
    "    mel_spectro_folder = os.path.join(SPECTRO_FOLDER, folder_name)\n",
    "    if not os.path.exists(mel_spectro_folder):\n",
    "        os.makedirs(mel_spectro_folder)\n",
    "    \n",
    "    for i, chunk in enumerate(correct_chunks):\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        S = librosa.feature.melspectrogram(y=chunk.numpy(), sr=16000, n_mels=128, fmax=8000)\n",
    "        S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "        librosa.display.specshow(S_dB, sr=16000, x_axis='time', y_axis='mel', fmax=8000)\n",
    "        # plt.colorbar(format='%+2.0f dB')  # Usuń lub skomentuj tę linię, aby usunąć legendę\n",
    "        plt.axis('off')\n",
    "        plt.savefig(os.path.join(mel_spectro_folder, f'{recording_name}_mel_chunk_{i}.jpg'), bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Iterate through each genre folder\n",
    "for genre_folder in os.listdir(DATA_FOLDER):\n",
    "    genre_path = os.path.join(DATA_FOLDER, genre_folder)\n",
    "    if os.path.isdir(genre_path):\n",
    "        print(\"Processing genre:\", genre_folder)\n",
    "        \n",
    "        # Iterate through each recording within the genre folder\n",
    "        for recording_name in os.listdir(genre_path):\n",
    "            recording_path = os.path.join(genre_path, recording_name)\n",
    "            if recording_name.endswith(\".wav\"):\n",
    "                print(\"Processing recording:\", recording_name)\n",
    "\n",
    "                try:\n",
    "                    # Load and normalize the WAV file\n",
    "                    wave = load_wav_16k_mono(recording_path)\n",
    "                    wave = normalize_wav(wave)\n",
    "\n",
    "                    # Split into chunks\n",
    "                    chunks = split_wav_into_chunks(wave)\n",
    "\n",
    "                    # Initialize list to store correctness\n",
    "                    correctness = []\n",
    "\n",
    "                    # Determine correctness of each chunk\n",
    "                    for chunk_index, chunk in enumerate(chunks):\n",
    "                        # Calculate number of times amplitude > 0.3\n",
    "                        high_amplitude_count = tf.reduce_sum(tf.cast(chunk > 0.65, tf.int32))\n",
    "                        # Check if count is greater than or equal to 3\n",
    "                        if high_amplitude_count >= 3:\n",
    "                            correctness.append(True)\n",
    "                        else:\n",
    "                            correctness.append(False)\n",
    "\n",
    "                    # Save mel spectrogram for correct chunks\n",
    "                    correct_chunks = [chunk for chunk, correct in zip(chunks, correctness) if correct]\n",
    "                    save_mel_spectrograms(correct_chunks, genre_folder, os.path.splitext(recording_name)[0])\n",
    "\n",
    "                    print(\"Mel spectrograms saved successfully!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing {recording_name}: {e}\")\n",
    "                    continue\n",
    "\n",
    "print(\"All recordings processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4edbd-483d-47f5-9eb7-caab485c3021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
